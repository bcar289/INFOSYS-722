{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pkey: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      " |-- Year ending: string (nullable = true)\n",
      " |-- Airport of departure: string (nullable = true)\n",
      " |-- Purpose of visit: string (nullable = true)\n",
      " |-- Country of permanent residence: string (nullable = true)\n",
      " |-- Total visitor spend: double (nullable = true)\n",
      " |-- Total visitors: integer (nullable = true)\n",
      "\n",
      "['Pkey', 'Year', 'Quarter', 'Year ending', 'Airport of departure', 'Purpose of visit', 'Country of permanent residence', 'Total visitor spend', 'Total visitors']\n"
     ]
    }
   ],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.appName('logistic_regression_adv').getOrCreate()\n",
    "\n",
    "# If you're getting an error with numpy, please type 'sudo pip3 install numpy --user' into the console.\n",
    "# If you're getting an error with another package, type 'sudo pip3 install PACKAGENAME --user'. \n",
    "# Replace PACKAGENAME with the relevant package (such as pandas, etc).\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Import data and print schema - columns is another way to view the data's features.\n",
    "df = spark.read.csv('Datasets/IVS_Country.csv', header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pkey</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year ending</th>\n",
       "      <th>Airport of departure</th>\n",
       "      <th>Purpose of visit</th>\n",
       "      <th>Country of permanent residence</th>\n",
       "      <th>Total visitor spend</th>\n",
       "      <th>Total visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Business</td>\n",
       "      <td>Africa and Middle East</td>\n",
       "      <td>4.266524e+06</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Business</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.325885e+08</td>\n",
       "      <td>67277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Business</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1.558969e+07</td>\n",
       "      <td>3596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Business</td>\n",
       "      <td>China</td>\n",
       "      <td>9.490118e+06</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Business</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.481106e+06</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pkey  Year  Quarter Year ending Airport of departure Purpose of visit  \\\n",
       "0     1  1997        4  YEDec 1997             Auckland         Business   \n",
       "1     2  1997        4  YEDec 1997             Auckland         Business   \n",
       "2     3  1997        4  YEDec 1997             Auckland         Business   \n",
       "3     4  1997        4  YEDec 1997             Auckland         Business   \n",
       "4     5  1997        4  YEDec 1997             Auckland         Business   \n",
       "\n",
       "  Country of permanent residence  Total visitor spend  Total visitors  \n",
       "0         Africa and Middle East         4.266524e+06            1684  \n",
       "1                      Australia         1.325885e+08           67277  \n",
       "2                         Canada         1.558969e+07            3596  \n",
       "3                          China         9.490118e+06            4510  \n",
       "4                        Germany         5.481106e+06            1889  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas.\n",
    "import pandas as pd\n",
    "\n",
    "# Take the first five rows of data, and visualise.\n",
    "pd.DataFrame(df.take(5), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pkey</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year ending</th>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>YEDec 1997</td>\n",
       "      <td>YEDec 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airport of departure</th>\n",
       "      <td>Auckland</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>Auckland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose of visit</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country of permanent residence</th>\n",
       "      <td>Africa and Middle East</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>China</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total visitor spend</th>\n",
       "      <td>4.26652e+06</td>\n",
       "      <td>1.32589e+08</td>\n",
       "      <td>1.55897e+07</td>\n",
       "      <td>9.49012e+06</td>\n",
       "      <td>5.48111e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total visitors</th>\n",
       "      <td>1684</td>\n",
       "      <td>67277</td>\n",
       "      <td>3596</td>\n",
       "      <td>4510</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0            1  \\\n",
       "Pkey                                                 1            2   \n",
       "Year                                              1997         1997   \n",
       "Quarter                                              4            4   \n",
       "Year ending                                 YEDec 1997   YEDec 1997   \n",
       "Airport of departure                          Auckland     Auckland   \n",
       "Purpose of visit                              Business     Business   \n",
       "Country of permanent residence  Africa and Middle East    Australia   \n",
       "Total visitor spend                        4.26652e+06  1.32589e+08   \n",
       "Total visitors                                    1684        67277   \n",
       "\n",
       "                                          2            3            4  \n",
       "Pkey                                      3            4            5  \n",
       "Year                                   1997         1997         1997  \n",
       "Quarter                                   4            4            4  \n",
       "Year ending                      YEDec 1997   YEDec 1997   YEDec 1997  \n",
       "Airport of departure               Auckland     Auckland     Auckland  \n",
       "Purpose of visit                   Business     Business     Business  \n",
       "Country of permanent residence       Canada        China      Germany  \n",
       "Total visitor spend             1.55897e+07  9.49012e+06  5.48111e+06  \n",
       "Total visitors                         3596         4510         1889  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To visualise the first five columns, simply add transpose. \n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2009</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1999</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2002</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  count\n",
       "0   2003    832\n",
       "1   2007    832\n",
       "2   2018    208\n",
       "3   2015    832\n",
       "4   2006    832\n",
       "5   2013    832\n",
       "6   1997    208\n",
       "7   2014    832\n",
       "8   2004    832\n",
       "9   1998    832\n",
       "10  2012    832\n",
       "11  2009    832\n",
       "12  2016    832\n",
       "13  2001    832\n",
       "14  2005    832\n",
       "15  2000    832\n",
       "16  2010    832\n",
       "17  2011    832\n",
       "18  2008    832\n",
       "19  2017    832\n",
       "20  1999    832\n",
       "21  2002    832"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use group by and count to find out how many data points we have for each class in our predictor. \n",
    "df.groupby('year').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pkey</th>\n",
       "      <td>17056</td>\n",
       "      <td>8528.5</td>\n",
       "      <td>4923.787431100846</td>\n",
       "      <td>1</td>\n",
       "      <td>17056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>17056</td>\n",
       "      <td>2007.5</td>\n",
       "      <td>5.9270657557172814</td>\n",
       "      <td>1997</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quarter</th>\n",
       "      <td>17056</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1289220372929016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total visitors</th>\n",
       "      <td>11292</td>\n",
       "      <td>15576.741232731138</td>\n",
       "      <td>33229.303734004156</td>\n",
       "      <td>1</td>\n",
       "      <td>314584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                   1                   2     3       4\n",
       "summary         count                mean              stddev   min     max\n",
       "Pkey            17056              8528.5   4923.787431100846     1   17056\n",
       "Year            17056              2007.5  5.9270657557172814  1997    2018\n",
       "Quarter         17056                 2.5  1.1289220372929016     1       4\n",
       "Total visitors  11292  15576.741232731138  33229.303734004156     1  314584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a for loop to find all columns that belong to the integer data type. \n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'int']\n",
    "\n",
    "# Selecting the numeric features, generating summary statistics, and converting to a Pandas DataFrame.\n",
    "df.select(numeric_features).describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total visitor spend</th>\n",
       "      <td>11292</td>\n",
       "      <td>5.09246119696264E7</td>\n",
       "      <td>1.0193863986366412E8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.235333092E9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                   1                     2    3  \\\n",
       "summary              count                mean                stddev  min   \n",
       "Total visitor spend  11292  5.09246119696264E7  1.0193863986366412E8  2.4   \n",
       "\n",
       "                                 4  \n",
       "summary                        max  \n",
       "Total visitor spend  1.235333092E9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a for loop to find all columns that belong to the integer data type. \n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'double']\n",
    "\n",
    "# Selecting the numeric features, generating summary statistics, and converting to a Pandas DataFrame.\n",
    "df.select(numeric_features).describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages.\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)\n",
    "\n",
    "# First create a string indexer which converts every string into a number, such as male = 0 and female = 1.\n",
    "# A number will be assigned to every category in the column.\n",
    "country_indexer = StringIndexer(inputCol='Country of permanent residence',outputCol='countryIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can one hot encode these numbers. This converts the various outputs into a single vector.\n",
    "# Multiple columns are collapsed into one. \n",
    "# This makes it easier to process when you have multiple classes.\n",
    "country_encoder = OneHotEncoder(inputCol='countryIndex',outputCol='countryVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, using vector assembler to turn all of these columns into one column (named features).\n",
    "assembler = VectorAssembler(inputCols=['countryVec'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`label`' given input columns: [Pkey, Year ending, Country of permanent residence, Quarter, Purpose of visit, Total visitors, features, Year, Total visitor spend, countryVec, Airport of departure, countryIndex];;\\n'Project ['label, features#416]\\n+- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, countryVec#403, UDF(named_struct(countryVec, countryVec#403)) AS features#416]\\n   +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, if (isnull(cast(countryIndex#391 as double))) null else UDF(cast(countryIndex#391 as double)) AS countryVec#403]\\n      +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, UDF(cast(Country of permanent residence#6 as string)) AS countryIndex#391]\\n         +- Relation[Pkey#0,Year#1,Quarter#2,Year ending#3,Airport of departure#4,Purpose of visit#5,Country of permanent residence#6,Total visitor spend#7,Total visitors#8] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o141.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`label`' given input columns: [Pkey, Year ending, Country of permanent residence, Quarter, Purpose of visit, Total visitors, features, Year, Total visitor spend, countryVec, Airport of departure, countryIndex];;\n'Project ['label, features#416]\n+- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, countryVec#403, UDF(named_struct(countryVec, countryVec#403)) AS features#416]\n   +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, if (isnull(cast(countryIndex#391 as double))) null else UDF(cast(countryIndex#391 as double)) AS countryVec#403]\n      +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, UDF(cast(Country of permanent residence#6 as string)) AS countryIndex#391]\n         +- Relation[Pkey#0,Year#1,Quarter#2,Year ending#3,Airport of departure#4,Purpose of visit#5,Country of permanent residence#6,Total visitor spend#7,Total visitors#8] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:266)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:280)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:280)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$6.apply(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2845)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1131)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41903b89845e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Remove all variables other than features and label.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpipe_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \"\"\"\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`label`' given input columns: [Pkey, Year ending, Country of permanent residence, Quarter, Purpose of visit, Total visitors, features, Year, Total visitor spend, countryVec, Airport of departure, countryIndex];;\\n'Project ['label, features#416]\\n+- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, countryVec#403, UDF(named_struct(countryVec, countryVec#403)) AS features#416]\\n   +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, countryIndex#391, if (isnull(cast(countryIndex#391 as double))) null else UDF(cast(countryIndex#391 as double)) AS countryVec#403]\\n      +- Project [Pkey#0, Year#1, Quarter#2, Year ending#3, Airport of departure#4, Purpose of visit#5, Country of permanent residence#6, Total visitor spend#7, Total visitors#8, UDF(cast(Country of permanent residence#6 as string)) AS countryIndex#391]\\n         +- Relation[Pkey#0,Year#1,Quarter#2,Year ending#3,Airport of departure#4,Purpose of visit#5,Country of permanent residence#6,Total visitor spend#7,Total visitors#8] csv\\n\""
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Then go through our steps. It's essentially sequential to the above.\n",
    "pipeline = Pipeline(stages=[country_indexer, country_encoder, assembler])\n",
    "\n",
    "# Now that we've got a number of steps, let's apply it to the DataFrame.\n",
    "pipeline_model = pipeline.fit(df)\n",
    "\n",
    "# Incorporate results into a new DataFrame.\n",
    "pipe_df = pipeline_model.transform(df)\n",
    "\n",
    "# Remove all variables other than features and label. \n",
    "pipe_df = pipe_df.select('label', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
